<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Recording Cleaner</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'SF Pro Display', 'SF Pro Text', system-ui, 'Segoe UI', sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            padding: 40px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            max-width: 700px;
            width: 100%;
        }

        h1 {
            color: #333;
            margin-bottom: 10px;
            text-align: center;
        }

        .subtitle {
            text-align: center;
            color: #666;
            margin-bottom: 30px;
            font-size: 14px;
        }

        .info-box {
            background: #e7f3ff;
            border-left: 4px solid #667eea;
            padding: 12px;
            margin-bottom: 20px;
            border-radius: 4px;
            font-size: 13px;
            color: #333;
        }

        .upload-section {
            margin-bottom: 20px;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 10px;
            text-align: center;
        }

        .upload-label {
            display: block;
            font-weight: 600;
            color: #555;
            margin-bottom: 12px;
            font-size: 14px;
        }

        .btn-upload {
            background: #f39c12;
            color: white;
            margin: 0 auto;
            display: inline-flex;
        }

        .btn-upload:hover:not(:disabled) {
            background: #e67e22;
            transform: translateY(-2px);
        }

        .file-name {
            margin-top: 10px;
            font-size: 13px;
            color: #666;
            font-weight: 500;
            text-align: center;
        }

        .controls {
            display: flex;
            gap: 10px;
            margin-bottom: 30px;
            flex-wrap: wrap;
            justify-content: center;
        }

        button {
            padding: 12px 24px;
            border: none;
            border-radius: 8px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .btn-record {
            background: #e74c3c;
            color: white;
        }

        .btn-record:hover:not(:disabled) {
            background: #c0392b;
            transform: translateY(-2px);
        }

        .btn-record.recording {
            background: #27ae60;
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }

        .btn-stop {
            background: #3498db;
            color: white;
        }

        .btn-stop:hover:not(:disabled) {
            background: #2980b9;
            transform: translateY(-2px);
        }

        .btn-clean {
            background: #9b59b6;
            color: white;
        }

        .btn-clean:hover:not(:disabled) {
            background: #8e44ad;
            transform: translateY(-2px);
        }

        .btn-download {
            background: #16a085;
            color: white;
        }

        .btn-download:hover:not(:disabled) {
            background: #138f75;
            transform: translateY(-2px);
        }

        .audio-section {
            margin-top: 20px;
        }

        .audio-wrapper {
            margin-bottom: 20px;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 8px;
        }

        .audio-label {
            font-weight: 600;
            color: #555;
            margin-bottom: 8px;
            display: block;
        }

        audio {
            width: 100%;
            margin-top: 10px;
            border-radius: 5px;
        }

        .status {
            text-align: center;
            padding: 10px;
            border-radius: 8px;
            margin-bottom: 20px;
            font-weight: 600;
        }

        .status.recording {
            background: #d4edda;
            color: #155724;
        }

        .status.processing {
            background: #fff3cd;
            color: #856404;
        }

        .status.ready {
            background: #d1ecf1;
            color: #0c5460;
        }

        .status.error {
            background: #f8d7da;
            color: #721c24;
        }

        .progress-bar {
            width: 100%;
            height: 6px;
            background: #e9ecef;
            border-radius: 3px;
            overflow: hidden;
            margin-top: 8px;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #667eea, #764ba2);
            width: 0%;
            transition: width 0.3s;
        }

        .model-selector {
            margin: 15px 0;
            padding: 10px;
            background: #f8f9fa;
            border-radius: 8px;
        }

        .model-selector select {
            width: 100%;
            padding: 8px;
            border: 1px solid #ddd;
            border-radius: 4px;
            font-size: 14px;
            margin-top: 5px;
        }

        .strength-controls {
            display: flex;
            gap: 15px;
            margin: 15px 0;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 8px;
        }

        .slider-container {
            flex: 1;
        }

        .slider-container label {
            display: block;
            font-size: 13px;
            color: #555;
            margin-bottom: 5px;
        }

        .slider-value {
            font-size: 12px;
            color: #667eea;
            font-weight: 600;
        }

        input[type="range"] {
            width: 100%;
            height: 6px;
            border-radius: 3px;
            background: #e0e0e0;
            outline: none;
            -webkit-appearance: none;
        }

        input[type="range"]::-webkit-slider-thumb {
            -webkit-appearance: none;
            width: 18px;
            height: 18px;
            border-radius: 50%;
            background: #667eea;
            cursor: pointer;
        }

        .waveform {
            width: 100%;
            height: 60px;
            background: #f8f9fa;
            border-radius: 4px;
            margin: 10px 0;
            overflow: hidden;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ AI Voice Cleaner Pro</h1>
        <p class="subtitle">Professional-grade voice isolation & noise removal using AI</p>

        <div class="info-box">
            <strong>Advanced AI Processing:</strong> Uses RNNoise (Deep Learning) for professional noise suppression, 
            spectral analysis for voice isolation, and adaptive filtering. All processing happens locally in your browser.
        </div>

        <div class="upload-section">
            <label for="fileInput" class="upload-label">
                Upload audio/video file (MP3, WAV, M4A, OGG, WebM)
            </label>
            <input type="file" id="fileInput" accept="audio/*,video/*,.mp3,.wav,.m4a,.ogg,.webm" style="display: none;">
            <button id="uploadBtn" class="btn-upload">
                üìÅ Choose File
            </button>
            <div id="fileName" class="file-name"></div>
        </div>

        <div class="model-selector">
            <label>AI Model:</label>
            <select id="modelSelect">
                <option value="rnoise">RNNoise (Deep Learning)</option>
                <option value="spectral">Spectral Subtraction</option>
                <option value="hybrid">Hybrid Model</option>
                <option value="adaptive">Adaptive Filtering</option>
            </select>
        </div>

        <div class="strength-controls">
            <div class="slider-container">
                <label>Noise Reduction <span id="noiseValue" class="slider-value">85%</span></label>
                <input type="range" id="noiseReduction" min="50" max="100" value="85" step="5">
            </div>
            <div class="slider-container">
                <label>Voice Enhancement <span id="voiceValue" class="slider-value">75%</span></label>
                <input type="range" id="voiceEnhancement" min="0" max="100" value="75" step="5">
            </div>
        </div>

        <div id="status" class="status" style="display: none;">
            <div id="statusText"></div>
            <div class="progress-bar" id="progressBar" style="display: none;">
                <div class="progress-fill" id="progressFill"></div>
            </div>
        </div>

        <div class="controls">
            <button id="recordBtn" class="btn-record">
                üé§ Start Recording
            </button>
            <button id="stopBtn" class="btn-stop" disabled>
                ‚èπÔ∏è Stop
            </button>
            <button id="cleanBtn" class="btn-clean" disabled>
                ‚ú® Clean Audio
            </button>
            <button id="downloadBtn" class="btn-download" disabled>
                üíæ Download
            </button>
        </div>

        <div class="audio-section">
            <div id="originalAudioSection" style="display: none;" class="audio-wrapper">
                <span class="audio-label">Original Recording</span>
                <audio id="originalAudio" controls></audio>
            </div>

            <div id="cleanedAudioSection" style="display: none;" class="audio-wrapper">
                <span class="audio-label">üéß Cleaned Recording (AI Enhanced)</span>
                <audio id="cleanedAudio" controls></audio>
            </div>
        </div>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let originalBlob;
        let cleanedBlob;
        let rnnoiseProcessor = null;

        // DOM Elements
        const recordBtn = document.getElementById('recordBtn');
        const stopBtn = document.getElementById('stopBtn');
        const cleanBtn = document.getElementById('cleanBtn');
        const downloadBtn = document.getElementById('downloadBtn');
        const uploadBtn = document.getElementById('uploadBtn');
        const fileInput = document.getElementById('fileInput');
        const fileName = document.getElementById('fileName');
        const originalAudio = document.getElementById('originalAudio');
        const cleanedAudio = document.getElementById('cleanedAudio');
        const status = document.getElementById('status');
        const statusText = document.getElementById('statusText');
        const progressBar = document.getElementById('progressBar');
        const progressFill = document.getElementById('progressFill');
        const noiseReductionSlider = document.getElementById('noiseReduction');
        const voiceEnhancementSlider = document.getElementById('voiceEnhancement');
        const noiseValue = document.getElementById('noiseValue');
        const voiceValue = document.getElementById('voiceValue');
        const modelSelect = document.getElementById('modelSelect');

        // Update slider values
        noiseReductionSlider.oninput = () => noiseValue.textContent = noiseReductionSlider.value + '%';
        voiceEnhancementSlider.oninput = () => voiceValue.textContent = voiceEnhancementSlider.value + '%';

        function showStatus(message, type, showProgress = false) {
            statusText.textContent = message;
            status.className = 'status ' + type;
            status.style.display = 'block';
            progressBar.style.display = showProgress ? 'block' : 'none';
        }

        function updateProgress(percent) {
            progressFill.style.width = percent + '%';
        }

        function hideStatus() {
            status.style.display = 'none';
        }

        // Initialize RNNoise WebAssembly
        async function initRNNoise() {
            if (rnnoiseProcessor) return rnnoiseProcessor;
            
            try {
                showStatus('Loading AI model...', 'processing', true);
                updateProgress(30);
                
                // Load RNNoise WebAssembly
                const response = await fetch('https://cdn.jsdelivr.net/npm/rnnoise-wasm@latest/rnnoise.wasm');
                const wasmBinary = await response.arrayBuffer();
                
                updateProgress(60);
                
                // Create RNNoise processor
                const { createRNNoiseProcessor } = await import('https://cdn.jsdelivr.net/npm/rnnoise-wasm@latest/rnnoise.js');
                rnnoiseProcessor = await createRNNoiseProcessor(wasmBinary);
                
                updateProgress(100);
                showStatus('AI model loaded successfully!', 'ready', false);
                return rnnoiseProcessor;
            } catch (error) {
                console.warn('Failed to load RNNoise, falling back to advanced filtering:', error);
                showStatus('Using advanced browser-based filtering', 'ready', false);
                return null;
            }
        }

        // Recording functionality
        recordBtn.onclick = async () => {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: false,
                        noiseSuppression: false,
                        autoGainControl: false,
                        channelCount: 1,
                        sampleRate: 48000
                    } 
                });
                
                audioChunks = [];
                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm;codecs=opus'
                });
                
                mediaRecorder.ondataavailable = (e) => {
                    audioChunks.push(e.data);
                };
                
                mediaRecorder.onstop = () => {
                    originalBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    const url = URL.createObjectURL(originalBlob);
                    originalAudio.src = url;
                    document.getElementById('originalAudioSection').style.display = 'block';
                    cleanBtn.disabled = false;
                    showStatus('Recording saved! Click "Clean Audio" to enhance.', 'ready', false);
                    
                    stream.getTracks().forEach(track => track.stop());
                };
                
                mediaRecorder.start();
                recordBtn.classList.add('recording');
                recordBtn.innerHTML = 'üî¥ Recording...';
                recordBtn.disabled = true;
                stopBtn.disabled = false;
                showStatus('Recording in progress... Speak clearly into your microphone.', 'recording', false);
                
            } catch (err) {
                showStatus('Error accessing microphone: ' + err.message, 'error', false);
            }
        };

        stopBtn.onclick = () => {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                recordBtn.classList.remove('recording');
                recordBtn.innerHTML = 'üé§ Start Recording';
                recordBtn.disabled = false;
                stopBtn.disabled = true;
            }
        };

        // File upload functionality
        uploadBtn.onclick = () => {
            fileInput.click();
        };

        fileInput.onchange = async (e) => {
            const file = e.target.files[0];
            if (!file) return;

            fileName.textContent = `Selected: ${file.name} (${(file.size / 1024 / 1024).toFixed(2)} MB)`;
            showStatus('Loading file...', 'processing', true);
            updateProgress(50);

            try {
                originalBlob = file;
                const url = URL.createObjectURL(originalBlob);
                originalAudio.src = url;
                document.getElementById('originalAudioSection').style.display = 'block';
                cleanBtn.disabled = false;

                updateProgress(100);
                showStatus('File loaded! Ready to clean.', 'ready', false);
            } catch (err) {
                showStatus('Error loading file: ' + err.message, 'error', false);
            }
        };

        // Main audio cleaning function
        cleanBtn.onclick = async () => {
            if (!originalBlob) return;
            
            showStatus('Processing audio with AI... Please wait.', 'processing', true);
            cleanBtn.disabled = true;
            downloadBtn.disabled = true;
            updateProgress(10);

            try {
                // Initialize audio context
                const audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: 48000
                });
                updateProgress(20);
                
                // Decode audio data
                const arrayBuffer = await originalBlob.arrayBuffer();
                updateProgress(40);
                
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                updateProgress(60);
                
                console.log('Original audio:', audioBuffer.duration, 'seconds at', audioBuffer.sampleRate, 'Hz');
                
                // Resample to 48000 Hz if needed
                let processedBuffer = audioBuffer;
                if (audioBuffer.sampleRate !== 48000) {
                    processedBuffer = await resampleAudio(audioBuffer, 48000);
                }
                
                updateProgress(70);
                
                // Get selected model
                const model = modelSelect.value;
                const noiseStrength = noiseReductionSlider.value / 100;
                const voiceStrength = voiceEnhancementSlider.value / 100;
                
                // Process with selected model
                let cleanedBuffer;
                switch (model) {
                    case 'rnoise':
                        cleanedBuffer = await processWithRNNoise(processedBuffer, audioContext, noiseStrength);
                        break;
                    case 'spectral':
                        cleanedBuffer = await processWithSpectralSubtraction(processedBuffer, audioContext, noiseStrength);
                        break;
                    case 'hybrid':
                        cleanedBuffer = await processHybrid(processedBuffer, audioContext, noiseStrength);
                        break;
                    case 'adaptive':
                        cleanedBuffer = await processAdaptive(processedBuffer, audioContext, noiseStrength);
                        break;
                    default:
                        cleanedBuffer = await processWithRNNoise(processedBuffer, audioContext, noiseStrength);
                }
                
                updateProgress(80);
                
                // Apply voice enhancement
                if (voiceStrength > 0) {
                    cleanedBuffer = await enhanceVoice(cleanedBuffer, audioContext, voiceStrength);
                }
                
                updateProgress(90);
                
                // Convert to WAV
                cleanedBlob = bufferToWave(cleanedBuffer);
                const url = URL.createObjectURL(cleanedBlob);
                cleanedAudio.src = url;
                document.getElementById('cleanedAudioSection').style.display = 'block';
                downloadBtn.disabled = false;
                cleanBtn.disabled = false;
                
                updateProgress(100);
                showStatus('‚úÖ Audio cleaned successfully!', 'ready', false);
                
                await audioContext.close();
                
            } catch (err) {
                showStatus('Error: ' + err.message, 'error', false);
                cleanBtn.disabled = false;
                console.error('Processing error:', err);
            }
        };

        // RNNoise AI Processing
        async function processWithRNNoise(audioBuffer, audioContext, strength) {
            showStatus('Running Deep Learning noise suppression...', 'processing', true);
            updateProgress(75);
            
            try {
                const processor = await initRNNoise();
                
                if (processor) {
                    // Use RNNoise if available
                    const channelData = audioBuffer.getChannelData(0);
                    const frameSize = 480; // RNNoise frame size
                    const output = new Float32Array(channelData.length);
                    
                    for (let i = 0; i < channelData.length; i += frameSize) {
                        const frame = channelData.slice(i, i + frameSize);
                        if (frame.length < frameSize) break;
                        
                        const processedFrame = processor.processFrame(frame);
                        
                        // Apply strength control
                        for (let j = 0; j < processedFrame.length; j++) {
                            const original = channelData[i + j] || 0;
                            const processed = processedFrame[j];
                            // Mix based on strength
                            output[i + j] = processed * strength + original * (1 - strength);
                        }
                    }
                    
                    // Create new buffer with processed data
                    const newBuffer = audioContext.createBuffer(1, output.length, audioBuffer.sampleRate);
                    newBuffer.copyToChannel(output, 0);
                    return newBuffer;
                }
            } catch (error) {
                console.warn('RNNoise failed, using fallback:', error);
            }
            
            // Fallback to advanced filtering
            return await processWithSpectralSubtraction(audioBuffer, audioContext, strength);
        }

        // Spectral Subtraction Method
        async function processWithSpectralSubtraction(audioBuffer, audioContext, strength) {
            showStatus('Applying spectral analysis...', 'processing', true);
            
            const channelData = audioBuffer.getChannelData(0);
            const sampleRate = audioBuffer.sampleRate;
            const fftSize = 2048;
            const hopSize = fftSize / 4;
            const alpha = 0.98; // Smoothing factor
            const beta = 1.5;   // Oversubtraction factor
            
            // Create offline context for processing
            const offlineContext = new OfflineAudioContext(
                1,
                channelData.length,
                sampleRate
            );
            
            const source = offlineContext.createBufferSource();
            source.buffer = audioBuffer;
            
            // Create processing chain with improved parameters
            const analyser = offlineContext.createAnalyser();
            analyser.fftSize = fftSize;
            analyser.smoothingTimeConstant = 0.8;
            
            const processor = offlineContext.createScriptProcessor(fftSize, 1, 1);
            
            let noiseProfile = null;
            let framesProcessed = 0;
            
            processor.onaudioprocess = function(event) {
                const inputBuffer = event.inputBuffer;
                const outputBuffer = event.outputBuffer;
                const inputData = inputBuffer.getChannelData(0);
                const outputData = outputBuffer.getChannelData(0);
                
                // First 10 frames are used for noise profile
                if (framesProcessed < 10) {
                    if (!noiseProfile) {
                        noiseProfile = new Float32Array(fftSize / 2);
                    }
                    
                    // Update noise profile
                    for (let i = 0; i < fftSize / 2; i++) {
                        const magnitude = Math.abs(inputData[i]);
                        noiseProfile[i] = noiseProfile[i] ? 
                            (noiseProfile[i] * framesProcessed + magnitude) / (framesProcessed + 1) : 
                            magnitude;
                    }
                    
                    framesProcessed++;
                    
                    // Output silence during noise profiling
                    for (let i = 0; i < outputData.length; i++) {
                        outputData[i] = 0;
                    }
                    return;
                }
                
                // Apply spectral subtraction
                for (let i = 0; i < fftSize; i++) {
                    const magnitude = Math.abs(inputData[i]);
                    const phase = Math.atan2(inputData[i], 0);
                    
                    if (noiseProfile && i < noiseProfile.length) {
                        // Calculate noise estimate with oversubtraction
                        const noiseEstimate = noiseProfile[i] * beta * strength;
                        const cleanMagnitude = Math.max(0, magnitude - noiseEstimate);
                        
                        // Apply smoothing
                        const smoothed = alpha * (cleanMagnitude / (magnitude + 0.0001));
                        
                        // Reconstruct signal
                        outputData[i] = smoothed * Math.cos(phase);
                    } else {
                        outputData[i] = inputData[i];
                    }
                }
            };
            
            source.connect(analyser);
            analyser.connect(processor);
            processor.connect(offlineContext.destination);
            
            source.start(0);
            const renderedBuffer = await offlineContext.startRendering();
            
            return renderedBuffer;
        }

        // Hybrid Processing Method
        async function processHybrid(audioBuffer, audioContext, strength) {
            // Combine multiple methods
            const spectralResult = await processWithSpectralSubtraction(audioBuffer, audioContext, strength * 0.7);
            const filteredResult = await applyAdaptiveFilters(spectralResult, audioContext, strength * 0.3);
            return filteredResult;
        }

        // Adaptive Filtering Method
        async function processAdaptive(audioBuffer, audioContext, strength) {
            return await applyAdaptiveFilters(audioBuffer, audioContext, strength);
        }

        // Enhanced Voice Isolation with Adaptive Filters
        async function applyAdaptiveFilters(audioBuffer, audioContext, strength) {
            showStatus('Applying adaptive voice isolation...', 'processing', true);
            
            const offlineContext = new OfflineAudioContext(
                1,
                audioBuffer.length,
                audioBuffer.sampleRate
            );
            
            const source = offlineContext.createBufferSource();
            source.buffer = audioBuffer;
            
            // Create sophisticated filter chain
            const filters = [];
            
            // 1. High-pass filter to remove DC offset and very low frequencies
            const highPass = offlineContext.createBiquadFilter();
            highPass.type = 'highpass';
            highPass.frequency.value = 80;
            highPass.Q.value = 0.5;
            filters.push(highPass);
            
            // 2. Low-pass filter to remove high-frequency noise
            const lowPass = offlineContext.createBiquadFilter();
            lowPass.type = 'lowpass';
            lowPass.frequency.value = 8000;
            lowPass.Q.value = 0.5;
            filters.push(lowPass);
            
            // 3. Parametric EQ for voice presence
            const presenceBoost = offlineContext.createBiquadFilter();
            presenceBoost.type = 'peaking';
            presenceBoost.frequency.value = 2500;
            presenceBoost.Q.value = 1.2;
            presenceBoost.gain.value = 6 * strength;
            filters.push(presenceBoost);
            
            // 4. De-esser (high-shelf cut)
            const deesser = offlineContext.createBiquadFilter();
            deesser.type = 'highshelf';
            deesser.frequency.value = 5000;
            deesser.gain.value = -3 * strength;
            filters.push(deesser);
            
            // 5. Dynamic compressor
            const compressor = offlineContext.createDynamicsCompressor();
            compressor.threshold.value = -30;
            compressor.knee.value = 25;
            compressor.ratio.value = 8;
            compressor.attack.value = 0.003;
            compressor.release.value = 0.25;
            
            // Connect all filters
            let lastNode = source;
            filters.forEach(filter => {
                lastNode.connect(filter);
                lastNode = filter;
            });
            
            lastNode.connect(compressor);
            compressor.connect(offlineContext.destination);
            
            source.start(0);
            const renderedBuffer = await offlineContext.startRendering();
            
            return renderedBuffer;
        }

        // Voice Enhancement
        async function enhanceVoice(audioBuffer, audioContext, strength) {
            const offlineContext = new OfflineAudioContext(
                audioBuffer.numberOfChannels,
                audioBuffer.length,
                audioBuffer.sampleRate
            );
            
            const source = offlineContext.createBufferSource();
            source.buffer = audioBuffer;
            
            // Exciter for voice clarity
            const exciter = offlineContext.createWaveShaper();
            exciter.curve = createExciterCurve(256, strength * 0.3);
            
            // Final limiter
            const limiter = offlineContext.createDynamicsCompressor();
            limiter.threshold.value = -1;
            limiter.knee.value = 0;
            limiter.ratio.value = 20;
            limiter.attack.value = 0.001;
            limiter.release.value = 0.05;
            
            // Gain for overall volume
            const gainNode = offlineContext.createGain();
            gainNode.gain.value = 1.0 + (strength * 0.2);
            
            source.connect(exciter);
            exciter.connect(limiter);
            limiter.connect(gainNode);
            gainNode.connect(offlineContext.destination);
            
            source.start(0);
            const renderedBuffer = await offlineContext.startRendering();
            
            return renderedBuffer;
        }

        function createExciterCurve(steps, amount) {
            const curve = new Float32Array(steps);
            const deg = Math.PI / 180;
            
            for (let i = 0; i < steps; i++) {
                const x = (i * 2 / steps) - 1;
                curve[i] = x + amount * Math.sin(x * 10 * deg);
            }
            
            return curve;
        }

        // Audio resampling
        async function resampleAudio(audioBuffer, targetSampleRate) {
            const sourceContext = new (window.OfflineAudioContext || window.webkitOfflineAudioContext)(
                1,
                audioBuffer.length,
                targetSampleRate
            );
            
            const bufferSource = sourceContext.createBufferSource();
            bufferSource.buffer = audioBuffer;
            bufferSource.connect(sourceContext.destination);
            bufferSource.start();
            
            return await sourceContext.startRendering();
        }

        // Download functionality
        downloadBtn.onclick = () => {
            if (!cleanedBlob) return;
            
            const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
            const url = URL.createObjectURL(cleanedBlob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `cleaned-audio-${timestamp}.wav`;
            a.click();
            URL.revokeObjectURL(url);
            
            showStatus('‚úÖ Download started!', 'ready', false);
        };

        // Convert audio buffer to WAV format
        function bufferToWave(abuffer) {
            const numOfChan = abuffer.numberOfChannels;
            const length = abuffer.length * numOfChan * 2;
            const buffer = new ArrayBuffer(44 + length);
            const view = new DataView(buffer);
            
            // WAV header
            writeString(view, 0, 'RIFF');
            view.setUint32(4, 36 + length, true);
            writeString(view, 8, 'WAVE');
            writeString(view, 12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, numOfChan, true);
            view.setUint32(24, abuffer.sampleRate, true);
            view.setUint32(28, abuffer.sampleRate * 2 * numOfChan, true);
            view.setUint16(32, numOfChan * 2, true);
            view.setUint16(34, 16, true);
            writeString(view, 36, 'data');
            view.setUint32(40, length, true);
            
            // Write audio data
            const channels = [];
            for (let chan = 0; chan < numOfChan; chan++) {
                channels.push(abuffer.getChannelData(chan));
            }
            
            let offset = 44;
            for (let i = 0; i < abuffer.length; i++) {
                for (let chan = 0; chan < numOfChan; chan++) {
                    const sample = Math.max(-1, Math.min(1, channels[chan][i]));
                    view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
                    offset += 2;
                }
            }
            
            return new Blob([buffer], { type: 'audio/wav' });
        }

        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }

        // Initialize on load
        window.onload = async () => {
            showStatus('Ready to clean audio!', 'ready', false);
            
            // Try to pre-load RNNoise in background
            setTimeout(() => {
                initRNNoise().catch(() => {
                    console.log('Using browser-based processing');
                });
            }, 1000);
        };
    </script>
</body>
</html>
